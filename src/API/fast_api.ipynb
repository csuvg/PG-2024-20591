{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastapi uvicorn nest-asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py:67> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\main.py\", line 577, in run\n",
      "    server.run()\n",
      "  File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py\", line 65, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py\", line 360, in __wakeup\n",
      "    self.__step()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py\", line 68, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py\", line 328, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:     Started server process [20696]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8001 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Predicciones: [[1. 0. 0. 0. 0.]]\n",
      "Índice de clase predicha: 0\n",
      "Clase predicha: Chinche salivosa\n",
      "Confianza: 1.0\n",
      "INFO:     127.0.0.1:56922 - \"POST /predict/ HTTP/1.1\" 200 OK\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "Predicciones: [[0. 0. 0. 0. 1.]]\n",
      "Índice de clase predicha: 4\n",
      "Clase predicha: Roya purpura\n",
      "Confianza: 1.0\n",
      "INFO:     127.0.0.1:56935 - \"POST /predict/ HTTP/1.1\" 200 OK\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "Predicciones: [[0. 0. 0. 0. 1.]]\n",
      "Índice de clase predicha: 4\n",
      "Clase predicha: Roya purpura\n",
      "Confianza: 1.0\n",
      "INFO:     127.0.0.1:56942 - \"POST /predict/ HTTP/1.1\" 200 OK\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
      "Predicciones: [[1. 0. 0. 0. 0.]]\n",
      "Índice de clase predicha: 0\n",
      "Clase predicha: Chinche salivosa\n",
      "Confianza: 1.0\n",
      "INFO:     127.0.0.1:56953 - \"POST /predict/ HTTP/1.1\" 200 OK\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "Predicciones: [[1.6981954e-26 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "Índice de clase predicha: 4\n",
      "Clase predicha: Roya purpura\n",
      "Confianza: 1.0\n",
      "INFO:     127.0.0.1:56970 - \"POST /predict/ HTTP/1.1\" 200 OK\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "Predicciones: [[1. 0. 0. 0. 0.]]\n",
      "Índice de clase predicha: 0\n",
      "Clase predicha: Chinche salivosa\n",
      "Confianza: 1.0\n",
      "INFO:     127.0.0.1:56990 - \"POST /predict/ HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from PIL import Image\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Permitir que FastAPI se ejecute en Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Inicializar la aplicación de FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Cargar el modelo entrenado de Keras en formato HDF5 (.h5)\n",
    "model = tf.keras.models.load_model('../Results/ensemble_model.h5')  # Asegúrate de que la ruta sea correcta\n",
    "\n",
    "# Clases de tu modelo (asegúrate de que el orden es correcto)\n",
    "class_names = ['Chinche salivosa', 'Clororis', 'Hoja sana', 'Roya naranja', 'Roya purpura']\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict_image(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        # Leer la imagen subida\n",
    "        contents = await file.read()\n",
    "        image = Image.open(io.BytesIO(contents))\n",
    "\n",
    "        # Convertir la imagen a RGB y redimensionarla\n",
    "        image = image.convert(\"RGB\")\n",
    "        image = image.resize((256, 256))  # Asegúrate de que coincide con INPUT_SHAPE\n",
    "\n",
    "        # Convertir la imagen a un array de NumPy y a float32\n",
    "        img_array = np.array(image).astype(np.float32)\n",
    "\n",
    "        # Añadir dimensión para el batch\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Realizar la predicción\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "        class_name = class_names[predicted_class]\n",
    "        confidence = float(np.max(predictions))  # Asegúrate de convertir a float\n",
    "\n",
    "        # Imprimir para depuración\n",
    "        print(\"Predicciones:\", predictions)\n",
    "        print(\"Índice de clase predicha:\", predicted_class)\n",
    "        print(\"Clase predicha:\", class_name)\n",
    "        print(\"Confianza:\", confidence)\n",
    "\n",
    "        return {\"prediction\": class_name, \"confidence\": confidence}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=f\"Error al procesar la imagen: {str(e)}\")\n",
    "\n",
    "# Iniciar el servidor de FastAPI\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'Roya purpura', 'confidence': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL de la API (usa la URL pública generada por ngrok)\n",
    "url = \"https://0088-34-142-189-227.ngrok-free.app/predict/\"\n",
    "\n",
    "# Subir una imagen para predecir (ajusta la ruta de la imagen según tu ubicación)\n",
    "with open(\"../Chinche.jpg\", \"rb\") as image_file:\n",
    "    response = requests.post(url, files={\"file\": image_file})\n",
    "\n",
    "# Verificar si la respuesta es correcta antes de decodificar\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        json_response = response.json()  # Intentar decodificar JSON\n",
    "        print(json_response)\n",
    "    except ValueError as e:\n",
    "        print(\"Error al decodificar JSON:\", e)\n",
    "        print(\"Contenido de la respuesta:\", response.text)\n",
    "else:\n",
    "    print(f\"Error en la solicitud: {response.status_code}\")\n",
    "    print(\"Contenido de la respuesta:\", response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

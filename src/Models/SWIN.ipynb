{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando dispositivo: cuda\n",
      "Nombre de la GPU: NVIDIA GeForce GTX 1650 Ti\n",
      "Memoria total de la GPU: 4.29 GB\n"
     ]
    }
   ],
   "source": [
    "# Configurar el dispositivo y mostrar información\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilizando dispositivo: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Nombre de la GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria total de la GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (224, 224)\n",
    "SEED = 123\n",
    "BATCH_SIZE = 16  # Aumentado para GPU\n",
    "LEARNING_RATE = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar semilla para reproducibilidad\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "images_dir = '../arcgis-survey-images-new-last/arcgis-survey-images-new-last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases encontradas: ['Chinche salivosa', 'Clororis', 'Hoja sana', 'Roya naranja', 'Roya purpura']\n"
     ]
    }
   ],
   "source": [
    "# Obtener nombres de clases y asignar etiquetas numéricas\n",
    "class_names = sorted([d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))])\n",
    "class_to_label = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "print(f\"Clases encontradas: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear listas para almacenar rutas de imágenes y etiquetas\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(images_dir, class_name)\n",
    "    for fname in os.listdir(class_dir):\n",
    "        if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_paths.append(os.path.join(class_dir, fname))\n",
    "            labels.append(class_to_label[class_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el DataFrame\n",
    "data_df = pd.DataFrame({\n",
    "    'filepath': image_paths,\n",
    "    'label': labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Distribución original de clases:\\n{data_df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "train_df, val_df = train_test_split(\n",
    "    data_df,\n",
    "    test_size=0.2,\n",
    "    stratify=data_df['label'],\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling de clases minoritarias en el conjunto de entrenamiento\n",
    "df_list = [train_df[train_df['label'] == i] for i in train_df['label'].unique()]\n",
    "max_count = train_df['label'].value_counts().max()\n",
    "df_upsampled = [df if len(df) == max_count else resample(df, replace=True, n_samples=max_count, random_state=SEED) for df in df_list]\n",
    "train_df_balanced = pd.concat(df_upsampled)\n",
    "train_df_balanced = train_df_balanced.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(\"Distribución de clases después del upsampling:\")\n",
    "print(train_df_balanced['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el Dataset personalizado\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['filepath']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        image = read_image(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets\n",
    "train_dataset = ImageDataset(train_df_balanced, transform=transform)\n",
    "val_dataset = ImageDataset(val_df, transform=transform)\n",
    "\n",
    "# Crear dataloaders con pin_memory para GPU\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo ViT\n",
    "vit_model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    num_labels=len(class_names),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "vit_model = vit_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar Automatic Mixed Precision para acelerar el entrenamiento en GPU\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vit_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Definir el planificador de tasa de aprendizaje\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Configurar TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(loader, desc=\"Training\")):\n",
    "        print(f\"Processing batch {batch_idx+1}/{len(loader)}\")\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Automatic Mixed Precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Imprimir cada 10 batches\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Batch {batch_idx+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(loader, desc=\"Validating\")):\n",
    "        print(f\"Validating batch {batch_idx+1}/{len(loader)}\")\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Imprimir cada 10 batches\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Validation Batch {batch_idx+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el dispositivo a CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Utilizando dispositivo: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento principal\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(vit_model, train_loader, criterion, optimizer, device, scaler)\n",
    "    val_loss, val_acc = validate(vit_model, val_loader, criterion, device)\n",
    "    \n",
    "    # Registrar métricas en TensorBoard\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "    \n",
    "    # Imprimir progreso\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    # Ajustar la tasa de aprendizaje\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Guardar el mejor modelo\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(vit_model.state_dict(), 'best_model_vit.pth')\n",
    "        print(f'Modelo guardado con pérdida de validación: {val_loss:.4f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if optimizer.param_groups[0]['lr'] < 1e-6:\n",
    "        print(\"La tasa de aprendizaje ha caído por debajo del umbral. Deteniendo el entrenamiento.\")\n",
    "        break\n",
    "\n",
    "    # Mostrar uso de memoria GPU\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Uso de memoria GPU: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "writer.close()\n",
    "print(\"Entrenamiento completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de validación\n",
    "vit_model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = vit_model(inputs).logits\n",
    "        _, predicted = outputs.max(1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Etiqueta Verdadera')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

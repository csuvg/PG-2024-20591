{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3757 files belonging to 5 classes.\n",
      "Using 3006 files for training.\n",
      "Found 3757 files belonging to 5 classes.\n",
      "Using 751 files for validation.\n",
      "Pesos de clase: {0: 0.905421686746988, 1: 1.8329268292682928, 2: 0.8906666666666667, 3: 0.6534782608695652, 4: 1.4348448687350834}\n",
      "Image Shape: (32, 128, 128, 3)\n",
      "Epoch 1/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.4151 - loss: 2.2669 - val_accuracy: 0.5521 - val_loss: 2.4347 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - accuracy: 0.6969 - loss: 1.2763 - val_accuracy: 0.5990 - val_loss: 3.1012 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.7704 - loss: 0.9417 - val_accuracy: 0.7005 - val_loss: 2.2216 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - accuracy: 0.8429 - loss: 0.7701 - val_accuracy: 0.7083 - val_loss: 2.4535 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - accuracy: 0.8578 - loss: 0.7113 - val_accuracy: 0.6771 - val_loss: 2.6590 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.8818 - loss: 0.6193 - val_accuracy: 0.7682 - val_loss: 2.1114 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - accuracy: 0.8984 - loss: 0.5788 - val_accuracy: 0.6641 - val_loss: 3.5309 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.9255 - loss: 0.5307 - val_accuracy: 0.7083 - val_loss: 2.5690 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 249ms/step - accuracy: 0.8995 - loss: 0.5587 - val_accuracy: 0.7891 - val_loss: 2.4262 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 246ms/step - accuracy: 0.9333 - loss: 0.4431 - val_accuracy: 0.7578 - val_loss: 2.2930 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9393 - loss: 0.4481 - val_accuracy: 0.7865 - val_loss: 1.4178 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9458 - loss: 0.4026 - val_accuracy: 0.8333 - val_loss: 1.3565 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9541 - loss: 0.3940 - val_accuracy: 0.5365 - val_loss: 3.7251 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 250ms/step - accuracy: 0.9446 - loss: 0.3598 - val_accuracy: 0.7578 - val_loss: 2.1323 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - accuracy: 0.9629 - loss: 0.3095 - val_accuracy: 0.7839 - val_loss: 1.8612 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9773 - loss: 0.2707 - val_accuracy: 0.7760 - val_loss: 2.0797 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 261ms/step - accuracy: 0.9443 - loss: 0.3642 - val_accuracy: 0.6406 - val_loss: 2.5863 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 257ms/step - accuracy: 0.9429 - loss: 0.3707 - val_accuracy: 0.7891 - val_loss: 1.3954 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.9801 - loss: 0.2296 - val_accuracy: 0.8229 - val_loss: 1.2057 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.9961 - loss: 0.1822 - val_accuracy: 0.8438 - val_loss: 1.1907 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.9948 - loss: 0.1739 - val_accuracy: 0.8490 - val_loss: 1.1531 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9980 - loss: 0.1560 - val_accuracy: 0.8542 - val_loss: 1.1038 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9996 - loss: 0.1500 - val_accuracy: 0.8646 - val_loss: 1.0997 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.9991 - loss: 0.1440 - val_accuracy: 0.8724 - val_loss: 1.0614 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9994 - loss: 0.1358 - val_accuracy: 0.8698 - val_loss: 1.0435 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 249ms/step - accuracy: 0.9992 - loss: 0.1328 - val_accuracy: 0.8333 - val_loss: 1.1488 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 249ms/step - accuracy: 0.9917 - loss: 0.1466 - val_accuracy: 0.8724 - val_loss: 1.1592 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9982 - loss: 0.1262 - val_accuracy: 0.8802 - val_loss: 0.9681 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.9973 - loss: 0.1188 - val_accuracy: 0.8802 - val_loss: 0.9281 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9976 - loss: 0.1124 - val_accuracy: 0.8698 - val_loss: 1.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9981 - loss: 0.1078 - val_accuracy: 0.8828 - val_loss: 1.3532 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9895 - loss: 0.1380 - val_accuracy: 0.8672 - val_loss: 1.3403 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9934 - loss: 0.1143"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"New_Data.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1op5L6cCskTiujUSKbp50PlXNTxPpftt5\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\"\"\"### **Set Constants**\"\"\"\n",
    "\n",
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (128, 128)\n",
    "INPUT_SHAPE = (128, 128, 3)\n",
    "# DATASET_DIR = \"/kaggle/input/sugarcane-leaf-disease-dataset\"\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 250\n",
    "FINE_TUNE_POINT = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "DATASET_DIR = '../data/arcgis-survey-images-new'\n",
    "\n",
    "\"\"\"### **Load Image Datasets**\"\"\"\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    labels=\"inferred\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    labels=\"inferred\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    seed=SEED,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Calcular los pesos de clase\n",
    "class_names = train_ds.class_names\n",
    "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Pesos de clase:\", class_weights)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "augmented_train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "for example_image, example_label in train_ds.take(1):\n",
    "    break\n",
    "\n",
    "print(f\"Image Shape: {example_image.shape}\")\n",
    "\n",
    "\"\"\"### **Split Validation Dataset into a Validation DS and Test DS**\"\"\"\n",
    "\n",
    "validation_ds = validation_ds.shard(num_shards=2, index=0)\n",
    "test_ds = validation_ds.shard(num_shards=2, index=1)\n",
    "\n",
    "\"\"\"### **Visualize a Set of Training Data**\"\"\"\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.suptitle(\"Sugarcane Leafs (Healthy or Diseased)\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(BUFFER_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_ds = validation_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\"\"\"### **Load Base Model**\"\"\"\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Carga del modelo base con MobileNetV2\n",
    "base_model = MobileNetV2(input_shape=INPUT_SHAPE,\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "\n",
    "# Ajuste de las capas del modelo base\n",
    "for layer in base_model.layers[:FINE_TUNE_POINT]:  # Ajusta el número de capas descongeladas\n",
    "    layer.trainable = False\n",
    "\n",
    "# Definir el modelo completo con capas adicionales y Batch Normalization\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo con una tasa de aprendizaje adecuada\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\"\"\"### **Callbacks para Mejorar el Entrenamiento**\"\"\"\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, checkpoint]\n",
    "\n",
    "\"\"\"### **Fit the Model con Class Weights y Callbacks**\"\"\"\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\"\"\"### **Classification Report**\"\"\"\n",
    "\n",
    "metrics = history.history\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, metrics['loss'], label='Training Loss')\n",
    "plt.plot(history.epoch, metrics['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.ylim([0, max(max(metrics['loss']), max(metrics['val_loss']))])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.epoch, metrics['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.epoch, metrics['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "# Evaluación del modelo en el conjunto de test\n",
    "test_results = model.evaluate(test_ds, return_dict=True)\n",
    "print(\"Resultados de evaluación en test set:\")\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Predicción de etiquetas en el conjunto de test\n",
    "y_pred = model.predict(test_ds)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Reporte de clasificación\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "# Curvas ROC y AUC para cada clase\n",
    "y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Clase {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curvas ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

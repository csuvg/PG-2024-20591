{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autogluon\n",
    "# !pip install albumentations\n",
    "# !pip install pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall autogluon autogluon.vision autogluon.core autogluon.mxnet -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip setuptools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autogluon[vision]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autogluon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon.vision\n",
      "  Downloading autogluon.vision-0.6.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy<1.24,>=1.21 (from autogluon.vision)\n",
      "  Downloading numpy-1.23.5-cp311-cp311-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting pandas!=1.4.0,<1.6,>=1.2.5 (from autogluon.vision)\n",
      "  Using cached pandas-1.5.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting gluoncv<0.10.6,>=0.10.5 (from autogluon.vision)\n",
      "  Using cached gluoncv-0.10.5.post0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting Pillow<=9.4.0,>=9.3.0 (from autogluon.vision)\n",
      "  Downloading Pillow-9.4.0-cp311-cp311-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting timm<0.7.0,>=0.5.4 (from autogluon.vision)\n",
      "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ealda\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.vision) (3.8.3)\n",
      "Collecting autogluon.core==0.6.2 (from autogluon.vision)\n",
      "  Downloading autogluon.core-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting autogluon.multimodal==0.6.2 (from autogluon.vision)\n",
      "  Downloading autogluon.multimodal-0.6.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting scipy<1.10.0,>=1.5.4 (from autogluon.core==0.6.2->autogluon.vision)\n",
      "  Downloading scipy-1.9.3-cp311-cp311-win_amd64.whl.metadata (58 kB)\n",
      "Collecting scikit-learn<1.2,>=1.0.0 (from autogluon.core==0.6.2->autogluon.vision)\n",
      "  Downloading scikit_learn-1.1.3-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in c:\\users\\ealda\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==0.6.2->autogluon.vision) (5.9.8)\n",
      "Collecting networkx<3.0,>=2.3 (from autogluon.core==0.6.2->autogluon.vision)\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in c:\\users\\ealda\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==0.6.2->autogluon.vision) (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\users\\ealda\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==0.6.2->autogluon.vision) (2.32.3)\n",
      "Collecting dask<=2021.11.2,>=2021.09.1 (from autogluon.core==0.6.2->autogluon.vision)\n",
      "  Downloading dask-2021.11.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting distributed<=2021.11.2,>=2021.09.1 (from autogluon.core==0.6.2->autogluon.vision)\n",
      "  Downloading distributed-2021.11.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: boto3 in c:\\users\\ealda\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==0.6.2->autogluon.vision) (1.35.28)\n",
      "Collecting autogluon.common==0.6.2 (from autogluon.core==0.6.2->autogluon.vision)\n",
      "  Downloading autogluon.common-0.6.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jsonschema<=4.8.0 (from autogluon.multimodal==0.6.2->autogluon.vision)\n",
      "  Downloading jsonschema-4.8.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: seqeval<=1.2.2 in c:\\users\\ealda\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.multimodal==0.6.2->autogluon.vision) (1.2.2)\n",
      "Collecting evaluate<=0.3.0 (from autogluon.multimodal==0.6.2->autogluon.vision)\n",
      "  Downloading evaluate-0.3.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting accelerate<0.14,>=0.9 (from autogluon.multimodal==0.6.2->autogluon.vision)\n",
      "  Downloading accelerate-0.13.2-py3-none-any.whl.metadata (15 kB)\n",
      "INFO: pip is looking at multiple versions of autogluon-multimodal to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting autogluon.vision\n",
      "  Downloading autogluon.vision-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.core==0.6.1 (from autogluon.vision)\n",
      "  Downloading autogluon.core-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting autogluon.multimodal==0.6.1 (from autogluon.vision)\n",
      "  Downloading autogluon.multimodal-0.6.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting autogluon.vision\n",
      "  Downloading autogluon.vision-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting Pillow<9.1.0,>=9.0.1 (from autogluon.vision)\n",
      "  Downloading Pillow-9.0.1.tar.gz (49.5 MB)\n",
      "     ---------------------------------------- 0.0/49.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.8/49.5 MB 6.6 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 6.8/49.5 MB 22.1 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 16.5/49.5 MB 32.5 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 17.0/49.5 MB 32.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 26.2/49.5 MB 30.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 35.7/49.5 MB 31.5 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 39.3/49.5 MB 29.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 44.8/49.5 MB 28.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 49.5/49.5 MB 28.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting autogluon.core==0.6.0 (from autogluon.vision)\n",
      "  Downloading autogluon.core-0.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting autogluon.multimodal==0.6.0 (from autogluon.vision)\n",
      "  Downloading autogluon.multimodal-0.6.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting evaluate<=0.2.2 (from autogluon.multimodal==0.6.0->autogluon.vision)\n",
      "  Downloading evaluate-0.2.2-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting autogluon.vision\n",
      "  Downloading autogluon.vision-0.5.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy<1.23,>=1.21 (from autogluon.vision)\n",
      "  Downloading numpy-1.22.4.zip (11.5 MB)\n",
      "     ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "     -------------------------------- ------- 9.4/11.5 MB 49.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 11.5/11.5 MB 37.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pandas!=1.4.0,<1.5,>=1.2.5 (from autogluon.vision)\n",
      "  Downloading pandas-1.4.4.tar.gz (4.9 MB)\n",
      "     ---------------------------------------- 0.0/4.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.9/4.9 MB 37.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: still running...\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting timm<0.6.0,>=0.5.4 (from autogluon.vision)\n",
      "  Downloading timm-0.5.4-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting autogluon.core==0.5.3 (from autogluon.vision)\n",
      "  Downloading autogluon.core-0.5.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting scipy<1.8.0,>=1.5.4 (from autogluon.core==0.5.3->autogluon.vision)\n",
      "  Downloading scipy-1.7.3.tar.gz (36.1 MB)\n",
      "     ---------------------------------------- 0.0/36.1 MB ? eta -:--:--\n",
      "     ----------- --------------------------- 10.5/36.1 MB 50.4 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.7/36.1 MB 49.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 20.7/36.1 MB 7.6 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 25.7/36.1 MB 8.9 MB/s eta 0:00:02\n",
      "     --------------------------------------  35.4/36.1 MB 11.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 36.1/36.1 MB 11.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [118 lines of output]\n",
      "      setup.py:491: UserWarning: Unrecognized setuptools command ('dist_info --egg-base C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-modern-metadata-gckazbqo'), proceeding with generating Cython sources and expanding templates\n",
      "        warnings.warn(\"Unrecognized setuptools command ('{}'), proceeding with \"\n",
      "      setup.py:605: DeprecationWarning:\n",
      "      \n",
      "        `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "        of the deprecation of `distutils` itself. It will be removed for\n",
      "        Python >= 3.12. For older Python versions it will remain present.\n",
      "        It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "        For more details, see:\n",
      "          https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "      \n",
      "      \n",
      "        from numpy.distutils.core import setup\n",
      "      Running from SciPy source directory.\n",
      "      C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-build-env-yllwlht7\\overlay\\Lib\\site-packages\\pythran\\tables.py:4552: FutureWarning: In the future `np.bytes` will be defined as the corresponding NumPy scalar.\n",
      "        obj = getattr(themodule, elem)\n",
      "      WARNING: Overriding pythran description with argspec information for: numpy.random.power\n",
      "      Cythonizing sources\n",
      "      Running scipy\\linalg\\_generate_pyx.py\n",
      "      Running scipy\\special\\_generate_pyx.py\n",
      "      Running scipy\\stats\\_generate_pyx.py\n",
      "      Processing scipy\\cluster\\_hierarchy.pyx\n",
      "      Processing scipy\\cluster\\_optimal_leaf_ordering.pyx\n",
      "      Processing scipy\\cluster\\_vq.pyx\n",
      "      Processing scipy\\fftpack\\convolve.pyx\n",
      "      Processing scipy\\interpolate\\interpnd.pyx\n",
      "      Processing scipy\\interpolate\\_bspl.pyx\n",
      "      Processing scipy\\interpolate\\_ppoly.pyx\n",
      "      Processing scipy\\io\\matlab\\mio5_utils.pyx\n",
      "      Processing scipy\\io\\matlab\\mio_utils.pyx\n",
      "      Processing scipy\\io\\matlab\\streams.pyx\n",
      "      Processing scipy\\linalg\\cython_blas.pyx\n",
      "      Processing scipy\\linalg\\cython_lapack.pyx\n",
      "      Processing scipy\\linalg\\_decomp_update.pyx.in\n",
      "      Processing scipy\\linalg\\_matfuncs_sqrtm_triu.pyx\n",
      "      Processing scipy\\linalg\\_solve_toeplitz.pyx\n",
      "      Processing scipy\\ndimage\\src\\_cytest.pyx\n",
      "      Processing scipy\\ndimage\\src\\_ni_label.pyx\n",
      "      Processing scipy\\optimize\\_bglu_dense.pyx\n",
      "      Processing scipy\\optimize\\_group_columns.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      @cython.wraparound(False)\n",
      "      @cython.boundscheck(False)\n",
      "      def _handle_lhs_derivatives(const double[::1]t, int k, double xval,\n",
      "                                  double[::1, :] ab,\n",
      "                                  int kl, int ku,\n",
      "                                  const cnp.int_t[::1] deriv_ords,\n",
      "                                       ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      _bspl.pyx:292:34: 'int_t' is not a type identifier\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-install-zgit8km5\\scipy_ce52ee7b24564c189d3a65501537b3a4\\tools\\cythonize.py\", line 324, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-install-zgit8km5\\scipy_ce52ee7b24564c189d3a65501537b3a4\\tools\\cythonize.py\", line 320, in main\n",
      "          find_process_files(root_dir)\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-install-zgit8km5\\scipy_ce52ee7b24564c189d3a65501537b3a4\\tools\\cythonize.py\", line 309, in find_process_files\n",
      "          for result in pool.imap_unordered(lambda args: process(*args), jobs):\n",
      "        File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\pool.py\", line 873, in next\n",
      "          raise value\n",
      "        File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "          result = (True, func(*args, **kwds))\n",
      "                          ^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-install-zgit8km5\\scipy_ce52ee7b24564c189d3a65501537b3a4\\tools\\cythonize.py\", line 309, in <lambda>\n",
      "          for result in pool.imap_unordered(lambda args: process(*args), jobs):\n",
      "                                                         ^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-install-zgit8km5\\scipy_ce52ee7b24564c189d3a65501537b3a4\\tools\\cythonize.py\", line 243, in process\n",
      "          processor_function(fromfile, tofile, cwd=path)\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-install-zgit8km5\\scipy_ce52ee7b24564c189d3a65501537b3a4\\tools\\cythonize.py\", line 108, in process_pyx\n",
      "          raise Exception('Cython failed')\n",
      "      Exception: Cython failed\n",
      "      Traceback (most recent call last):\n",
      "        File \"setup.py\", line 357, in generate_cython\n",
      "          import pip\n",
      "      ModuleNotFoundError: No module named 'pip'\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "          return hook(metadata_directory, config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-build-env-yllwlht7\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 166, in prepare_metadata_for_build_wheel\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-build-env-yllwlht7\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 259, in run_setup\n",
      "          self).run_setup(setup_script=setup_script)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ealda\\AppData\\Local\\Temp\\pip-build-env-yllwlht7\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 150, in run_setup\n",
      "          exec(compile(code, __file__, 'exec'), locals())\n",
      "        File \"setup.py\", line 631, in <module>\n",
      "          setup_package()\n",
      "        File \"setup.py\", line 615, in setup_package\n",
      "          generate_cython()\n",
      "        File \"setup.py\", line 366, in generate_cython\n",
      "          raise RuntimeError(\"Running cythonize failed!\")\n",
      "      RuntimeError: Running cythonize failed!\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "                      # Take neighbor labels\n",
      "                      PyArray_ITER_RESET(itstruct)\n",
      "                      for ni in range(num_neighbors):\n",
      "                          neighbor_use_prev = (<np.int_t *> PyArray_ITER_DATA(itstruct))[0]\n",
      "                          neighbor_use_adjacent = (<np.int_t *> (<char *> PyArray_ITER_DATA(itstruct) + ss))[0]\n",
      "                                                   ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      _ni_label.pyx:332:46: 'int_t' is not a type identifier\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install autogluon.vision --ignore-requires-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogluon.vision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImagePredictor, ImageDataset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autogluon.vision'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.vision import ImagePredictor, ImageDataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de los Datos\n",
    "# -------------------------------\n",
    "\n",
    "# Directorio principal de imágenes\n",
    "images_dir = 'arcgis-survey-images'\n",
    "\n",
    "# Obtener las clases a partir de los nombres de los subdirectorios\n",
    "class_names = sorted([d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))])\n",
    "print(f\"Clases encontradas: {class_names}\")\n",
    "\n",
    "# Recopilar rutas de imágenes y etiquetas\n",
    "data = []\n",
    "for class_label in class_names:\n",
    "    class_dir = os.path.join(images_dir, class_label)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            data.append({'image': img_path, 'label': class_label})\n",
    "\n",
    "# Crear un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Total de imágenes: {len(df)}\")\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=123)\n",
    "print(f\"Entrenamiento: {len(train_df)} imágenes\")\n",
    "print(f\"Validación: {len(valid_df)} imágenes\")\n",
    "\n",
    "# Guardar los DataFrames en archivos CSV (opcional)\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "valid_df.to_csv('valid_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Preprocesamiento Avanzado (Opcional)\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las transformaciones de preprocesamiento\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        A.Resize(128, 128),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n",
    "        A.GaussianBlur(blur_limit=(3,7), p=0.2),\n",
    "        A.Canny(p=0.1),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    transformed = transform(image=image)\n",
    "    return transformed['image']\n",
    "\n",
    "# Aplicar las transformaciones y guardar las imágenes preprocesadas en un directorio temporal\n",
    "preprocessed_dir = 'preprocessed_images'\n",
    "if os.path.exists(preprocessed_dir):\n",
    "    shutil.rmtree(preprocessed_dir)\n",
    "os.makedirs(preprocessed_dir)\n",
    "\n",
    "def transformed_image_to_pil(tensor_image):\n",
    "    # Convertir el tensor de vuelta a PIL Image para guardarlo\n",
    "    image = tensor_image.permute(1, 2, 0).cpu().numpy()\n",
    "    image = (image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406])  # Desnormalizar\n",
    "    image = np.clip(image, 0, 1)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "def apply_preprocessing(df, split):\n",
    "    processed_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = row['image']\n",
    "        label = row['label']\n",
    "        processed_image = preprocess_image(img_path)\n",
    "        \n",
    "        # Guardar la imagen preprocesada\n",
    "        new_img_name = f\"{split}_{idx}.png\"\n",
    "        new_img_path = os.path.join(preprocessed_dir, new_img_name)\n",
    "        transformed_image = transformed_image_to_pil(processed_image)\n",
    "        transformed_image.save(new_img_path)\n",
    "        \n",
    "        processed_data.append({'image': new_img_path, 'label': label})\n",
    "        \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Nota: Aplicar preprocesamiento puede ser intensivo en tiempo y recursos.\n",
    "# Puedes comentar esta sección si prefieres dejar que AutoGluon maneje el preprocesamiento.\n",
    "\n",
    "# train_processed_df = apply_preprocessing(train_df, 'train')\n",
    "# valid_processed_df = apply_preprocessing(valid_df, 'valid')\n",
    "\n",
    "# Para este ejemplo, usaremos las rutas originales sin preprocesamiento adicional.\n",
    "train_processed_df = train_df.copy()\n",
    "valid_processed_df = valid_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Entrenamiento con AutoGluon\n",
    "# -------------------------------\n",
    "\n",
    "# Cargar los datos en el formato requerido por AutoGluon\n",
    "train_data = ImageDataset.from_df(train_processed_df, label='label')\n",
    "valid_data = ImageDataset.from_df(valid_processed_df, label='label')\n",
    "\n",
    "# Crear el predictor de AutoGluon\n",
    "predictor = ImagePredictor()\n",
    "\n",
    "# Entrenar el modelo\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=valid_data,  # Datos de validación para ajustar hiperparámetros\n",
    "    time_limit=3600,  # Tiempo máximo en segundos (por ejemplo, 1 hora)\n",
    "    presets='best_quality',  # Ajusta la calidad del entrenamiento\n",
    "    hyperparameters={\n",
    "        'model': 'resnet50',  # Puedes elegir diferentes arquitecturas\n",
    "    },\n",
    "    verbosity=2  # Nivel de detalle de los logs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Evaluación del Modelo\n",
    "# -------------------------------\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "test_performance = predictor.evaluate(valid_data)\n",
    "print(\"Resultados de evaluación en el conjunto de validación:\")\n",
    "print(test_performance)\n",
    "\n",
    "# Obtener predicciones en el conjunto de validación\n",
    "y_true = valid_processed_df['label'].values\n",
    "y_pred = predictor.predict(valid_data)\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Crear la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Etiqueta')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5. Visualización de Predicciones\n",
    "# -------------------------------\n",
    "\n",
    "# Mostrar algunas imágenes con sus predicciones\n",
    "def show_predictions(predictor, df, class_names, num_images=5):\n",
    "    samples = df.sample(n=num_images, random_state=42)\n",
    "    for idx, row in samples.iterrows():\n",
    "        img_path = row['image']\n",
    "        true_label = row['label']\n",
    "        # Cargar la imagen en formato compatible\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        pred_label = predictor.predict(ImageDataset.from_df(pd.DataFrame([row]), label='label')).iloc[0]\n",
    "        \n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Verdadero: {true_label}\\nPredicción: {pred_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Mostrar 5 predicciones aleatorias\n",
    "show_predictions(predictor, valid_processed_df, class_names, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 6. Guardar y Cargar el Modelo\n",
    "# -------------------------------\n",
    "\n",
    "# Guardar el modelo\n",
    "predictor.save(\"autogluon_plague_classifier\")\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "loaded_predictor = ImagePredictor.load(\"autogluon_plague_classifier\")\n",
    "\n",
    "# Evaluar nuevamente para verificar\n",
    "loaded_predictor.evaluate(valid_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

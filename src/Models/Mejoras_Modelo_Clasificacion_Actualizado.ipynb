{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a86fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # !pip install albumentations\n",
    "# # !pip install --upgrade tensorflow keras\n",
    "\n",
    "# !pip install --upgrade tensorflow tensorflow-addons keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d1f3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf\n",
    "# from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "\n",
    "# Configuración de hiperparámetros\n",
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (128, 128)\n",
    "INPUT_SHAPE = (128, 128, 3)\n",
    "SEED = 123\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 350\n",
    "FINE_TUNE_POINT = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Directorio del dataset\n",
    "DATASET_DIR = '../arcgis-survey-images-new'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa71505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para aplicar aumentación avanzada con Albumentations\n",
    "def advanced_augmentation(image):\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "        ], p=1),\n",
    "        A.GaussNoise(p=0.2),\n",
    "        A.MotionBlur(blur_limit=3, p=0.2),\n",
    "        A.CLAHE(clip_limit=2, p=0.2),\n",
    "    ])\n",
    "    augmented = transform(image=image)\n",
    "    return augmented[\"image\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "237c03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def mixup(data):\n",
    "    x, y = data\n",
    "    # Convertir y a float32\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    \n",
    "    # Generar un valor aleatorio para Mixup\n",
    "    lambda_value = tf.random.uniform([], minval=0, maxval=1)\n",
    "    \n",
    "    batch_size = tf.shape(x)[0]\n",
    "    index = tf.random.shuffle(tf.range(batch_size))\n",
    "\n",
    "    # Aplicar Mixup a las imágenes y etiquetas\n",
    "    mixed_x = lambda_value * x + (1 - lambda_value) * tf.gather(x, index)\n",
    "    mixed_y = lambda_value * y + (1 - lambda_value) * tf.gather(y, index)\n",
    "    return mixed_x, mixed_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65db2a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7514 files belonging to 6 classes.\n",
      "Using 6012 files for training.\n",
      "Found 7514 files belonging to 6 classes.\n",
      "Using 1502 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar el dataset desde directorios con preprocesamiento\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # Cambiar a 'categorical' para one-hot encoding\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # Cambiar a 'categorical' para one-hot encoding\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "\n",
    "# Aplicar Mixup al dataset de entrenamiento\n",
    "train_ds = train_ds.map(lambda x, y: mixup((x, y)))\n",
    "\n",
    "# Cachear y prefetch para optimización del pipeline\n",
    "train_ds = train_ds.map(lambda x, y: mixup((x, y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_ds = validation_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7b5bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Obtener el número de clases manualmente, si se conoce\n",
    "NUM_CLASSES = 6 # Reemplaza 5 con el número real de clases\n",
    "\n",
    "# Cargar el modelo base preentrenado (MobileNetV2)\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Congelar las capas iniciales del modelo\n",
    "for layer in base_model.layers[:FINE_TUNE_POINT]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Construir el modelo completo\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),  # Normalizar los valores de entrada\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),   # Normalización de batch\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),       # Dropout para evitar overfitting\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo utilizando CategoricalCrossentropy y suavizado de etiquetas\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "223c2108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 587ms/step - accuracy: 0.3615 - loss: 4.3447 - val_accuracy: 0.3422 - val_loss: 3.4961 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 539ms/step - accuracy: 0.4841 - loss: 2.9044 - val_accuracy: 0.4461 - val_loss: 2.7874 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 537ms/step - accuracy: 0.5326 - loss: 2.2793 - val_accuracy: 0.3322 - val_loss: 2.2498 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 540ms/step - accuracy: 0.5307 - loss: 1.9078 - val_accuracy: 0.4800 - val_loss: 1.8559 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 536ms/step - accuracy: 0.5401 - loss: 1.6866 - val_accuracy: 0.4913 - val_loss: 1.6252 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 541ms/step - accuracy: 0.5294 - loss: 1.5585 - val_accuracy: 0.4887 - val_loss: 1.5671 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 537ms/step - accuracy: 0.5276 - loss: 1.4891 - val_accuracy: 0.4887 - val_loss: 1.5168 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 536ms/step - accuracy: 0.5417 - loss: 1.4670 - val_accuracy: 0.4767 - val_loss: 1.4767 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 537ms/step - accuracy: 0.5453 - loss: 1.4504 - val_accuracy: 0.4893 - val_loss: 1.4458 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 537ms/step - accuracy: 0.5321 - loss: 1.4233 - val_accuracy: 0.4907 - val_loss: 1.3824 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 536ms/step - accuracy: 0.5379 - loss: 1.4142 - val_accuracy: 0.4660 - val_loss: 1.3754 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 546ms/step - accuracy: 0.5296 - loss: 1.4086 - val_accuracy: 0.4874 - val_loss: 1.3830 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 588ms/step - accuracy: 0.5386 - loss: 1.4099 - val_accuracy: 0.4913 - val_loss: 1.2990 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 583ms/step - accuracy: 0.5368 - loss: 1.4062 - val_accuracy: 0.4913 - val_loss: 1.3420 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 579ms/step - accuracy: 0.5567 - loss: 1.4112 - val_accuracy: 0.4860 - val_loss: 1.2612 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 556ms/step - accuracy: 0.5528 - loss: 1.4179 - val_accuracy: 0.4907 - val_loss: 1.3087 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 580ms/step - accuracy: 0.5560 - loss: 1.4162 - val_accuracy: 0.4907 - val_loss: 1.2507 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 577ms/step - accuracy: 0.5450 - loss: 1.3933 - val_accuracy: 0.4893 - val_loss: 1.2501 - learning_rate: 0.0010\n",
      "Epoch 19/50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Callbacks: EarlyStopping y ReduceLROnPlateau\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Visualizar los resultados del entrenamiento\n",
    "metrics = history.history\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.epoch, metrics['accuracy'], metrics['val_accuracy'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06714a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluación del modelo y visualización de resultados adicionales para evitar el overfitting\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "val_results = model.evaluate(validation_ds, return_dict=True)\n",
    "print(\"Resultados de evaluación en el conjunto de validación:\")\n",
    "for metric, value in val_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Predicción de etiquetas en el conjunto de validación\n",
    "y_pred = model.predict(validation_ds)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for _, y in validation_ds], axis=0)\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"Reporte de clasificación en el conjunto de validación:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=train_ds.class_names))\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, xticklabels=train_ds.class_names, yticklabels=train_ds.class_names, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "# Curvas ROC y AUC para cada clase en el conjunto de validación\n",
    "y_true_bin = label_binarize(y_true, classes=range(len(train_ds.class_names)))\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i in range(len(train_ds.class_names)):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Clase {train_ds.class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curvas ROC para cada clase')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

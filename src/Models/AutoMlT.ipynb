{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.layers.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mak\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensorV2\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autokeras\\__init__.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The AutoKeras Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertBlock\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalToNumerical\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autokeras\\auto_model.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m blocks\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph \u001b[38;5;28;01mas\u001b[39;00m graph_module\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autokeras\\blocks\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertBlock\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvBlock\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseBlock\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autokeras\\blocks\\basic.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_layers\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduction\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m block \u001b[38;5;28;01mas\u001b[39;00m block_module\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autokeras\\keras_layers.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautokeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_utils\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Preparación de los Datos\n",
    "# -------------------------------\n",
    "\n",
    "# Directorio principal de imágenes\n",
    "images_dir = 'arcgis-survey-images'\n",
    "\n",
    "# Verificar si el directorio existe\n",
    "if not os.path.isdir(images_dir):\n",
    "    raise FileNotFoundError(f\"El directorio '{images_dir}' no existe. Por favor, verifica la ruta.\")\n",
    "\n",
    "# Obtener las clases a partir de los nombres de los subdirectorios\n",
    "class_names = sorted([d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))])\n",
    "print(f\"Clases encontradas: {class_names}\")\n",
    "\n",
    "# Recopilar rutas de imágenes y etiquetas\n",
    "data = []\n",
    "for class_label in class_names:\n",
    "    class_dir = os.path.join(images_dir, class_label)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            data.append({'image': img_path, 'label': class_label})\n",
    "\n",
    "# Crear un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Total de imágenes: {len(df)}\")\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=123)\n",
    "print(f\"Entrenamiento: {len(train_df)} imágenes\")\n",
    "print(f\"Validación: {len(valid_df)} imágenes\")\n",
    "\n",
    "# Guardar los DataFrames en archivos CSV (opcional)\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "valid_df.to_csv('valid_data.csv', index=False)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Preprocesamiento Avanzado de Imágenes\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las transformaciones de preprocesamiento\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        A.Resize(128, 128),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n",
    "        A.GaussianBlur(blur_limit=(3,7), p=0.2),\n",
    "        A.Canny(p=0.1),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    transformed = transform(image=image)\n",
    "    return transformed['image']\n",
    "\n",
    "# Función para cargar y preprocesar imágenes\n",
    "def load_and_preprocess_image(path, label):\n",
    "    # Convertir la ruta de la imagen a un tensor\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    # Convertir a numpy para usar Albumentations\n",
    "    image = tf.numpy_function(preprocess_image, [path], tf.float32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Crear conjuntos de datos de TensorFlow\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_df['image'].values, train_df['label'].values))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((valid_df['image'].values, valid_df['label'].values))\n",
    "\n",
    "# Mapeo de etiquetas a índices\n",
    "label_to_index = {label: index for index, label in enumerate(class_names)}\n",
    "train_ds = train_ds.map(lambda x, y: (x, label_to_index[y]))\n",
    "valid_ds = valid_ds.map(lambda x, y: (x, label_to_index[y]))\n",
    "\n",
    "# Aplicar el preprocesamiento\n",
    "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "valid_ds = valid_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batching y Prefetching\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "valid_ds = valid_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Implementación de AutoML con AutoKeras\n",
    "# -------------------------------\n",
    "\n",
    "# Definir el ImageClassifier de AutoKeras\n",
    "clf = ak.ImageClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=10,  # Número de modelos a probar\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"Iniciando el entrenamiento con AutoKeras...\")\n",
    "clf.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=valid_ds\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = clf.evaluate(valid_ds)\n",
    "print(f'Precisión en el conjunto de validación: {accuracy:.4f}')\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluación del Modelo\n",
    "# -------------------------------\n",
    "\n",
    "# Obtener predicciones en el conjunto de validación\n",
    "# Para obtener etiquetas verdaderas y predichas\n",
    "def get_labels_and_predictions(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in dataset:\n",
    "        images, labels = batch\n",
    "        preds = model.predict(images)\n",
    "        preds = tf.argmax(preds, axis=1).numpy()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds)\n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = get_labels_and_predictions(clf, valid_ds)\n",
    "\n",
    "# Mapear índices a etiquetas\n",
    "index_to_label = {index: label for label, index in label_to_index.items()}\n",
    "y_true_labels = [index_to_label[idx] for idx in y_true]\n",
    "y_pred_labels = [index_to_label[idx] for idx in y_pred]\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))\n",
    "\n",
    "# Crear la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Etiqueta')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Visualización de Predicciones\n",
    "# -------------------------------\n",
    "\n",
    "# Mostrar algunas imágenes con sus predicciones\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def show_predictions(model, df, num_images=5):\n",
    "    samples = df.sample(n=num_images, random_state=42)\n",
    "    for idx, row in samples.iterrows():\n",
    "        img_path = row['image']\n",
    "        true_label = row['label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "        image_np = preprocess_image(img_path).transpose(1, 2, 0)\n",
    "        image_np = (image_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406])  # Desnormalizar\n",
    "        image_np = np.clip(image_np, 0, 1)\n",
    "        \n",
    "        # Expandir dimensiones para predecir\n",
    "        image_input = np.expand_dims(preprocess_image(img_path), axis=0)\n",
    "        pred = model.predict(image_input)\n",
    "        pred_class = np.argmax(pred, axis=1)[0]\n",
    "        pred_label = index_to_label[pred_class]\n",
    "        \n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(image_np)\n",
    "        plt.title(f\"Verdadero: {true_label}\\nPredicción: {pred_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Mostrar 5 predicciones aleatorias\n",
    "show_predictions(clf, valid_df, num_images=5)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Guardar y Cargar el Modelo\n",
    "# -------------------------------\n",
    "\n",
    "# Guardar el modelo\n",
    "clf.save(\"autokeras_plague_classifier\")\n",
    "print(\"Modelo guardado en 'autokeras_plague_classifier'.\")\n",
    "\n",
    "# Cargar el modelo guardado (opcional)\n",
    "loaded_clf = ak.ImageClassifier.load(\"autokeras_plague_classifier\")\n",
    "print(\"Modelo cargado desde 'autokeras_plague_classifier'.\")\n",
    "\n",
    "# Evaluar nuevamente para verificar\n",
    "loss, accuracy = loaded_clf.evaluate(valid_ds)\n",
    "print(f'Precisión del modelo cargado en el conjunto de validación: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4308 files belonging to 5 classes.\n",
      "Using 3447 files for training.\n",
      "Found 4308 files belonging to 5 classes.\n",
      "Using 861 files for validation.\n",
      "Epoch 1/50\n",
      "     77/Unknown \u001b[1m76s\u001b[0m 756ms/step - accuracy: 0.3823 - loss: 1.5664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_9\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 151\u001b[0m\n\u001b[0;32m    143\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39mcheckpoint_filepath,\n\u001b[0;32m    144\u001b[0m                                    save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    145\u001b[0m                                    monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    146\u001b[0m                                    mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    147\u001b[0m                                    save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Entrenamiento del modelo\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Cargar los mejores pesos del modelo\u001b[39;00m\n\u001b[0;32m    159\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_9\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)"
     ]
    }
   ],
   "source": [
    "\"\"\"Plague Classification Model with ArcGIS Data - Improved Version\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Parámetros de la red\n",
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (224, 224)  # Usamos 224x224 para MobileNetV2\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 350\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# # Montar Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# Directorio de las imágenes\n",
    "images_dir = '../arcgis-survey-images-new-last/arcgis-survey-images-new-last'\n",
    "\n",
    "# Número máximo de imágenes por clase\n",
    "MAX_IMAGES_PER_CLASS = 500\n",
    "\n",
    "# Función para limitar las imágenes a un máximo por clase\n",
    "def filter_max_images_per_class(ds, max_images_per_class, class_names):\n",
    "    class_counts = {class_name: 0 for class_name in class_names}\n",
    "    \n",
    "    def filter_fn(image, label):\n",
    "        class_name = class_names[label.numpy()]\n",
    "        if class_counts[class_name] < max_images_per_class:\n",
    "            class_counts[class_name] += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return ds.filter(lambda image, label: tf.py_function(\n",
    "        filter_fn, [image, label], tf.bool))\n",
    "\n",
    "# División de los datos en entrenamiento, validación y prueba\n",
    "train_ds = image_dataset_from_directory(\n",
    "    images_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    images_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Obtener los nombres de las clases\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Limitar las imágenes a 500 por clase en el dataset de entrenamiento\n",
    "train_ds = filter_max_images_per_class(train_ds, MAX_IMAGES_PER_CLASS, class_names)\n",
    "\n",
    "# Crear un conjunto de prueba a partir del conjunto de validación\n",
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batches // 2)\n",
    "val_ds = val_ds.skip(val_batches // 2)\n",
    "\n",
    "# Aplicar Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal_and_vertical'),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(0.2),\n",
    "])\n",
    "\n",
    "# Función para aplicar Data Augmentation y preprocesamiento\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = data_augmentation(image)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Optimizar rendimiento de los datasets\n",
    "train_ds = train_ds.cache().shuffle(BUFFER_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Cargar el modelo base (MobileNetV2)\n",
    "base_model = MobileNetV2(input_shape=INPUT_SHAPE,\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "\n",
    "# Congelar las capas iniciales del modelo base\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100  # Descongelar desde la capa 100 en adelante\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Construir el modelo completo\n",
    "inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./127.5, offset=-1)(x)  # Escalar entre [-1, 1] para MobileNetV2\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks para Early Stopping y Model Checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint_filepath = '/tmp/checkpoint.weights.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                   save_weights_only=True,\n",
    "                                   monitor='val_accuracy',\n",
    "                                   mode='max',\n",
    "                                   save_best_only=True)\n",
    "\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Cargar los mejores pesos del modelo\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "# Gráfica de la pérdida y precisión\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Entrenamiento')\n",
    "plt.plot(epochs_range, val_acc, label='Validación')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Precisión')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Entrenamiento')\n",
    "plt.plot(epochs_range, val_loss, label='Validación')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Pérdida')\n",
    "plt.show()\n",
    "\n",
    "# Evaluación en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"\\nResultados de evaluación en test set:\")\n",
    "print(f\"Pérdida en test: {test_loss:.4f}\")\n",
    "print(f\"Precisión en test: {test_accuracy:.4f}\")\n",
    "\n",
    "# Matriz de confusión y reporte de clasificación\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "conf_matrix = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt='g')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Etiqueta Verdadera')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo en formato .keras\n",
    "model.save('MobileNetV2-79%.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
